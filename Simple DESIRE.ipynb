{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UROP1100T (Spring 2018)\n",
    "\n",
    "## DESIRE: Distant Future Prediction in Dynamic Scenes with Interacting Agents\n",
    "\n",
    "[CVPR Paper](https://arxiv.org/pdf/1704.04394.pdf)\n",
    "\n",
    "[Supplementary Notes](http://www.robots.ox.ac.uk/~namhoon/doc/DESIRE-supp.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "    \n",
    "Subtract Y starting from X, not from itself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Generation Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_line_sep():\n",
    "    print('--------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data extract:\n",
      "['1', '172', '93.939', '-55.7615', '0', '-3.0066', '5.27149', '4', '10']\n",
      "--------------------------------------\n",
      "Filtered data extract:\n",
      "[1, 172, 93.939, -55.7615]\n",
      "--------------------------------------\n",
      "Data dictionary extract:\n",
      "[1, 93.939, -55.7615]\n"
     ]
    }
   ],
   "source": [
    "raw_data = []\n",
    "with open('raw_data/raw_record.csv', 'r') as csvfile:\n",
    "    csvreader = csv.reader(csvfile)\n",
    "    raw_data = list(csvreader)\n",
    "print('Raw data extract:')\n",
    "print(raw_data[0])\n",
    "print_line_sep()\n",
    "\n",
    "filtered_data = [[int(row[0]), int(row[1]), float(row[2]), float(row[3])] for row in raw_data]\n",
    "print('Filtered data extract:')\n",
    "print(filtered_data[0])\n",
    "print_line_sep()\n",
    "\n",
    "dict_data = {}\n",
    "for row in filtered_data:\n",
    "    time = row[0]\n",
    "    car = row[1]\n",
    "    x = row[2]\n",
    "    y = row[3]\n",
    "    \n",
    "    if car in dict_data:\n",
    "        dict_data[car].append([time, x, y])\n",
    "    else:\n",
    "        dict_data[car] = [[time, x, y]]\n",
    "print('Data dictionary extract:')\n",
    "print(dict_data[172][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_batches(x_seq_len, y_seq_len, batch_size):\n",
    "    batches = []\n",
    "    dict_data_keys = list(dict_data.keys())\n",
    "    \n",
    "    while(len(batches) < batch_size): # Fill up batches with batch_size rows of x+y_seq_len columns\n",
    "        car = random.choice(dict_data_keys)\n",
    "        batch = []\n",
    "        is_first = True\n",
    "        \n",
    "        # Loop through each row of that car until x+y_seq_len columns are found\n",
    "        for row in dict_data[car]:\n",
    "            time = row[0]\n",
    "            x = row[1]\n",
    "            y = row[2]\n",
    "            \n",
    "            # If first item of the sequence, just append\n",
    "            if is_first:\n",
    "                batch.append([time, x, y])\n",
    "                is_first = False\n",
    "                \n",
    "            # If not, check if time diff is 1\n",
    "            else:\n",
    "                prev_time = batch[-1][0]\n",
    "                \n",
    "                # If time diff is not 1,\n",
    "                # 1) Clear batch item\n",
    "                # 2) Start from current location as first batch item\n",
    "                if time - prev_time != 1:\n",
    "                    batch = []\n",
    "                    batch.append([time, x, y])\n",
    "                    \n",
    "                # Otherwise, just append to batch item\n",
    "                else:\n",
    "                    batch.append([time, x, y])\n",
    "            \n",
    "            # If batch item columns are enough, break\n",
    "            if len(batch) == x_seq_len + y_seq_len:\n",
    "                batches.append(batch)\n",
    "                break\n",
    "                \n",
    "    # Just keep (x,y)  \n",
    "    X_position_array = [[[item[1], item[2]] for item in batch[:x_seq_len]] for batch in batches]\n",
    "    Y_position_array = [[[item[1], item[2]] for item in batch[x_seq_len:]] for batch in batches]\n",
    "    \n",
    "    X_position_np = np.asarray(X_position_array).transpose(0, 2, 1)\n",
    "    Y_position_np = np.asarray(Y_position_array).transpose(0, 2, 1)\n",
    "    \n",
    "    X_position_tensor = Variable(torch.from_numpy(X_position_np).type(torch.FloatTensor)).cuda()\n",
    "    Y_position_tensor = Variable(torch.from_numpy(Y_position_np).type(torch.FloatTensor)).cuda()\n",
    "    \n",
    "    # Convert position to displacement\n",
    "    X_displacement_array = []\n",
    "    Y_displacement_array = []\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        x_first = X_position_array[i][0][0]\n",
    "        y_first = X_position_array[i][0][1]\n",
    "\n",
    "        X_batch = X_position_array[i]\n",
    "        X_displacement_array.append([[item[0] - x_first, item[1] - y_first] for item in X_batch])\n",
    "\n",
    "        Y_batch = Y_position_array[i]\n",
    "        Y_displacement_array.append([[item[0] - x_first, item[1] - y_first] for item in Y_batch])\n",
    "\n",
    "    X_displacement_np = np.asarray(X_displacement_array).transpose(0, 2, 1)    \n",
    "    Y_displacement_np = np.asarray(Y_displacement_array).transpose(0, 2, 1)\n",
    "    \n",
    "    X_displacement_tensor = Variable(torch.from_numpy(X_displacement_np).type(torch.FloatTensor)).cuda()\n",
    "    Y_displacement_tensor = Variable(torch.from_numpy(Y_displacement_np).type(torch.FloatTensor)).cuda()\n",
    "    \n",
    "    return X_position_tensor, Y_position_tensor, X_displacement_tensor, Y_displacement_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X positions:\n",
      "torch.Size([8, 2, 20])\n",
      "tensor([[ 26.0319,  26.3994,  26.7662,  27.1378,  27.5197,  27.9135,\n",
      "          28.3117,  28.7098,  29.1071,  29.5035,  29.8991,  30.2937,\n",
      "          30.6872,  31.0795,  31.4705,  31.8601,  32.2482,  32.6347,\n",
      "          33.0196,  33.4028],\n",
      "        [ -2.4178,  -2.4177,  -2.4176,  -2.4176,  -2.4174,  -2.4173,\n",
      "          -2.4172,  -2.4170,  -2.4169,  -2.4167,  -2.4166,  -2.4165,\n",
      "          -2.4164,  -2.4163,  -2.4162,  -2.4161,  -2.4160,  -2.4160,\n",
      "          -2.4159,  -2.4158]], device='cuda:0')\n",
      "--------------------------------------\n",
      "Y positions:\n",
      "torch.Size([8, 2, 40])\n",
      "tensor([[ 33.7844,  34.1642,  34.5423,  34.9187,  35.2933,  35.6662,\n",
      "          36.0374,  36.4069,  36.7747,  37.1417,  37.5136,  37.8958,\n",
      "          38.2898,  38.6883,  39.0867,  39.4842,  39.8808,  40.2766,\n",
      "          40.6715,  41.0652,  41.4577,  41.8489,  42.2387,  42.6270,\n",
      "          43.0137,  43.3988,  43.7823,  44.1640,  44.5440,  44.9223,\n",
      "          45.2989,  45.6737,  46.0468,  46.4181,  46.7878,  47.1557,\n",
      "          47.5229,  47.8950,  48.2773,  48.6715],\n",
      "        [ -2.4157,  -2.4157,  -2.4156,  -2.4155,  -2.4155,  -2.4154,\n",
      "          -2.4154,  -2.4153,  -2.4153,  -2.4152,  -2.4151,  -2.4150,\n",
      "          -2.4149,  -2.4148,  -2.4146,  -2.4145,  -2.4144,  -2.4142,\n",
      "          -2.4141,  -2.4140,  -2.4139,  -2.4138,  -2.4137,  -2.4137,\n",
      "          -2.4136,  -2.4135,  -2.4134,  -2.4134,  -2.4133,  -2.4132,\n",
      "          -2.4132,  -2.4131,  -2.4131,  -2.4130,  -2.4129,  -2.4129,\n",
      "          -2.4128,  -2.4128,  -2.4127,  -2.4125]], device='cuda:0')\n",
      "--------------------------------------\n",
      "X displacements:\n",
      "torch.Size([8, 2, 20])\n",
      "tensor([[ 0.0000,  0.3675,  0.7343,  1.1059,  1.4878,  1.8816,  2.2798,\n",
      "          2.6779,  3.0752,  3.4716,  3.8672,  4.2618,  4.6553,  5.0476,\n",
      "          5.4386,  5.8282,  6.2163,  6.6028,  6.9877,  7.3709],\n",
      "        [ 0.0000,  0.0001,  0.0002,  0.0002,  0.0003,  0.0005,  0.0006,\n",
      "          0.0008,  0.0009,  0.0010,  0.0012,  0.0013,  0.0014,  0.0015,\n",
      "          0.0016,  0.0017,  0.0018,  0.0018,  0.0019,  0.0020]], device='cuda:0')\n",
      "--------------------------------------\n",
      "Y displacements:\n",
      "torch.Size([8, 2, 40])\n",
      "tensor([[  7.7525,   8.1323,   8.5104,   8.8868,   9.2614,   9.6343,\n",
      "          10.0055,  10.3750,  10.7428,  11.1098,  11.4817,  11.8639,\n",
      "          12.2579,  12.6564,  13.0548,  13.4523,  13.8489,  14.2447,\n",
      "          14.6396,  15.0333,  15.4258,  15.8170,  16.2068,  16.5951,\n",
      "          16.9818,  17.3669,  17.7504,  18.1321,  18.5121,  18.8904,\n",
      "          19.2670,  19.6418,  20.0149,  20.3862,  20.7559,  21.1238,\n",
      "          21.4910,  21.8631,  22.2454,  22.6396],\n",
      "        [  0.0021,   0.0021,   0.0022,   0.0022,   0.0023,   0.0024,\n",
      "           0.0024,   0.0025,   0.0025,   0.0026,   0.0027,   0.0028,\n",
      "           0.0029,   0.0030,   0.0032,   0.0033,   0.0034,   0.0036,\n",
      "           0.0037,   0.0038,   0.0039,   0.0040,   0.0040,   0.0041,\n",
      "           0.0042,   0.0043,   0.0044,   0.0044,   0.0045,   0.0045,\n",
      "           0.0046,   0.0047,   0.0047,   0.0048,   0.0049,   0.0049,\n",
      "           0.0050,   0.0050,   0.0051,   0.0052]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "X_position_test, Y_position_test, X_displacement_test, Y_displacement_test = get_random_batches(20, 40, 8)\n",
    "\n",
    "print('X positions:')\n",
    "print(X_position_test.size())\n",
    "print(X_position_test[0])\n",
    "\n",
    "print_line_sep()\n",
    "\n",
    "print('Y positions:')\n",
    "print(Y_position_test.size())\n",
    "print(Y_position_test[0])\n",
    "\n",
    "print_line_sep()\n",
    "\n",
    "print('X displacements:')\n",
    "print(X_displacement_test.size())\n",
    "print(X_displacement_test[0])\n",
    "\n",
    "print_line_sep()\n",
    "\n",
    "print('Y displacements:')\n",
    "print(Y_displacement_test.size())\n",
    "print(Y_displacement_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleEncoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_dim, seq_len, num_layers,\n",
    "                 conv_output_dim, conv_kernel_size,\n",
    "                 gru_hidden_dim):\n",
    "        super(SampleEncoder, self).__init__()\n",
    "        \n",
    "        self.seq_len = seq_len\n",
    "        self.num_layers = num_layers\n",
    "        self.conv_output_dim = conv_output_dim\n",
    "        self.conv_kernel_size = conv_kernel_size\n",
    "        self.gru_hidden_dim = gru_hidden_dim\n",
    "        \n",
    "        # C = X or Y\n",
    "        # C_i, (input_dim, seq_len) -> tC_i, (conv_output_dim, seq_len)\n",
    "        self.conv = nn.Conv1d(input_dim, conv_output_dim, conv_kernel_size)\n",
    "\n",
    "        # tC_i, (conv_output_dim, seq_len) -> H_C_i, (gru_hidden_dim)\n",
    "        self.gru = nn.GRU(conv_output_dim, gru_hidden_dim, num_layers)\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        # Initial hidden vector is hidden_dim-dimensional and padded with 0\n",
    "        return Variable(torch.zeros(self.num_layers, batch_size, self.gru_hidden_dim)).cuda()\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        conv_output = self.conv(x)\n",
    "        conv_output = F.relu(conv_output)\n",
    "        \n",
    "        # conv_output has dimensions (batch_size, dim, seq_len)\n",
    "        # GRU accepts input tensor with dimensions (seq_len, batch_size, dim)\n",
    "        # TODO: Pad\n",
    "        conv_output = conv_output.permute(2, 0, 1)\n",
    "#         conv_output = conv_output.view(self.seq_len - self.conv_kernel_size + 1,\n",
    "#                                        batch_size,\n",
    "#                                        self.conv_output_dim)\n",
    "        \n",
    "        output, hidden = self.gru(conv_output, hidden)\n",
    "        \n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Variational Auto Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleCVAE(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, mu_dim, sigma_dim):\n",
    "        super(SampleCVAE, self).__init__()\n",
    "        \n",
    "        self.sigma_dim = sigma_dim\n",
    "\n",
    "        self.fc1 = nn.Linear(input_dim, output_dim)\n",
    "        self.fc_mu = nn.Linear(output_dim, mu_dim)\n",
    "        self.fc_sigma = nn.Linear(output_dim, sigma_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        output = self.fc1(x)\n",
    "        output = F.relu(output)\n",
    "        \n",
    "        mu = self.fc_mu(output)\n",
    "        sigma = torch.div(torch.exp(self.fc_sigma(output)), 2)\n",
    "        # Reparam trick\n",
    "        epsilon = Variable(torch.normal(torch.zeros(batch_size, self.sigma_dim),\n",
    "                           torch.ones(batch_size, self.sigma_dim))).cuda()\n",
    "\n",
    "        return mu + sigma*epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Connected Softmax Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleFCS(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(SampleFCS, self).__init__()\n",
    "        \n",
    "        self.fcs = nn.Linear(input_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.fcs(x)\n",
    "        output = F.softmax(output, dim=2)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleDecoder(nn.Module):\n",
    "    def __init__(self, input_dim, seq_len, num_layers, gru_hidden_dim, gru_output_dim, output_dim):\n",
    "        super(SampleDecoder, self).__init__()\n",
    "        \n",
    "        self.seq_len = seq_len\n",
    "        self.num_layers = num_layers\n",
    "        self.gru_hidden_dim = gru_hidden_dim\n",
    "        \n",
    "        self.gru = nn.GRU(input_dim, gru_output_dim, num_layers)\n",
    "        self.linear = nn.Linear(gru_output_dim, output_dim)\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        return Variable(torch.zeros(self.num_layers, batch_size, self.gru_hidden_dim)).cuda()\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        output, hidden = self.gru(x, hidden)\n",
    "        output = self.linear(output)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 5000\n",
    "batch_size = 512\n",
    "X_seq_len = 20\n",
    "Y_seq_len = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "\n",
    "# input_dim = 2        | input is a sequence of (x,y) coordinates (i.e. 2-dimensional)\n",
    "# seq_len = 20         | time sequence length of 20\n",
    "# conv_output_dim = 16 | 1D convolution with 16 output channels\n",
    "# conv_kernel_size = 3 | 1D convolution with kernel of width 3\n",
    "# gru_hidden_dim = 48  | 48-dimensional hidden vector\n",
    "#\n",
    "# Input: Tensor of size (batch_size, 2, 20)\n",
    "encoder1 = SampleEncoder(input_dim=2, seq_len=X_seq_len, num_layers=1,\n",
    "                         conv_output_dim=16, conv_kernel_size=3,\n",
    "                         gru_hidden_dim=48).cuda()\n",
    "\n",
    "# input_dim = 2        | input is a sequence of (x,y) coordinates (i.e. 2-dimensional)\n",
    "# seq_len = 40         | time sequence length of 40\n",
    "# conv_output_dim = 16 | 1D convolution with 16 output channels\n",
    "# conv_kernel_size = 1 | 1D convolution with kernel of width 1\n",
    "# gru_hidden_dim = 48  | 48-dimensional hidden vector\n",
    "#\n",
    "# Input: Tensor of size (batch_size, 2, 40)\n",
    "encoder2 = SampleEncoder(input_dim=2, seq_len=Y_seq_len, num_layers=1,\n",
    "                         conv_output_dim=16, conv_kernel_size=1,\n",
    "                         gru_hidden_dim=48).cuda()\n",
    "\n",
    "# input_dim = 96       | Concatenate encoder1's and encoder2's outputs (48-dim each) into 1 output (96-dim)\n",
    "# output_dim = 48      | Transform concatenated 96-dim vector into 48-dim vector\n",
    "# mu_dim = 48          | mu is 48-dim\n",
    "# sigma_dim = 48       | sigma is 48-dim\n",
    "#\n",
    "# Input: Tensor of size (batch_size, 48)\n",
    "cvae = SampleCVAE(input_dim=96, output_dim=48, mu_dim=48, sigma_dim=48).cuda()\n",
    "\n",
    "# input_dim = 48       |\n",
    "# output_dim = 48      |\n",
    "#\n",
    "# Input: Tensor of size (batch_size, 48)\n",
    "fcs = SampleFCS(input_dim=48, output_dim=48).cuda()\n",
    "\n",
    "# input_dim = 48       |\n",
    "# seq_len = 40         | time sequence length of 40\n",
    "# gru_hidden_dim = 48  |\n",
    "# gru_output_dim = 48  |\n",
    "# output_dim = 2       |\n",
    "#\n",
    "# Input: Tensor of size (40, batch_size, 48)\n",
    "decoder = SampleDecoder(input_dim=48, seq_len=40, num_layers=1,\n",
    "                        gru_hidden_dim=48, gru_output_dim=48,\n",
    "                        output_dim=2).cuda()\n",
    "\n",
    "# Loss\n",
    "kld = nn.KLDivLoss()\n",
    "mse = nn.MSELoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam([\n",
    "    {'params': encoder1.parameters()},\n",
    "    {'params': encoder2.parameters()},\n",
    "    {'params': cvae.parameters()},\n",
    "    {'params': fcs.parameters()},\n",
    "    {'params': decoder.parameters()}\n",
    "], lr=learning_rate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 1) Total Loss: 8.877, KLD Loss: 1.845, MSE Loss: 7.032\n",
      "\n",
      "(Epoch 2) Total Loss: 9.341, KLD Loss: 1.805, MSE Loss: 7.536\n",
      "\n",
      "(Epoch 3) Total Loss: 8.712, KLD Loss: 1.815, MSE Loss: 6.897\n",
      "\n",
      "(Epoch 4) Total Loss: 7.404, KLD Loss: 1.811, MSE Loss: 5.593\n",
      "\n",
      "(Epoch 5) Total Loss: 8.738, KLD Loss: 1.813, MSE Loss: 6.925\n",
      "\n",
      "(Epoch 6) Total Loss: 7.810, KLD Loss: 1.834, MSE Loss: 5.976\n",
      "\n",
      "(Epoch 7) Total Loss: 8.291, KLD Loss: 1.832, MSE Loss: 6.460\n",
      "\n",
      "(Epoch 8) Total Loss: 9.302, KLD Loss: 1.852, MSE Loss: 7.450\n",
      "\n",
      "(Epoch 9) Total Loss: 8.895, KLD Loss: 1.878, MSE Loss: 7.017\n",
      "\n",
      "(Epoch 10) Total Loss: 8.000, KLD Loss: 1.819, MSE Loss: 6.181\n",
      "\n",
      "(Epoch 11) Total Loss: 8.560, KLD Loss: 1.870, MSE Loss: 6.690\n",
      "\n",
      "(Epoch 12) Total Loss: 9.106, KLD Loss: 1.895, MSE Loss: 7.211\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# writer = SummaryWriter()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    X_position, Y_position, X_displacement, Y_displacement = get_random_batches(X_seq_len, Y_seq_len, batch_size)\n",
    "    \n",
    "#     writer.add_scalars('data/X', {\n",
    "#         'x': X.permute(0, 2, 1)[0][0][0],\n",
    "#         'y': Y.permute(0, 2, 1)[0][0][0]\n",
    "#     }, epoch)\n",
    "    \n",
    "    running_kld_loss = 0.0\n",
    "    running_mse_loss = 0.0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    #optimizer\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Encoder 1\n",
    "    e1_hidden = encoder1.init_hidden(batch_size)\n",
    "    e1_output, e1_last_hidden = encoder1(X_displacement, e1_hidden)\n",
    "    H_X = e1_last_hidden\n",
    "\n",
    "    # Encoder 2\n",
    "    e2_hidden = encoder2.init_hidden(batch_size)\n",
    "    e2_output, e2_last_hidden = encoder2(Y_displacement, e2_hidden)\n",
    "    H_Y = e2_last_hidden\n",
    "\n",
    "    # CVAE\n",
    "    H_XY = torch.cat([H_X, H_Y], 2)\n",
    "    z = cvae(H_XY)\n",
    "\n",
    "    # FCS\n",
    "    beta_z = fcs(z)\n",
    "    \n",
    "    # Decoder\n",
    "    xz = H_X*beta_z\n",
    "    hxz = xz\n",
    "    for i in range(39):\n",
    "        hxz = torch.cat((hxz, Variable(torch.zeros(1, batch_size, 48)).cuda()), 0)\n",
    "    decoder_hidden = decoder.init_hidden(batch_size)\n",
    "    output, last_hidden = decoder(hxz, decoder_hidden)\n",
    "\n",
    "    # Reconstruction\n",
    "    x0 = X_position.permute(2, 0, 1)[-1]\n",
    "    delta_x0 = output[0]    \n",
    "    y0_hat = x0 + delta_x0\n",
    "    y_hat = y0_hat.unsqueeze(0)\n",
    "    \n",
    "#     print(y0_hat[0])\n",
    "#     print(Y_position.permute(2, 0, 1)[0][0])\n",
    "    \n",
    "    for i in range(1, Y_seq_len):\n",
    "        yi = y_hat[i - 1]\n",
    "        delta_xi = output[i]\n",
    "        yi_hat = yi + delta_xi\n",
    "        yi_hat = yi_hat.unsqueeze(0)\n",
    "        y_hat = torch.cat((y_hat, yi_hat), 0)\n",
    "        \n",
    "    # Minimise loss\n",
    "    # KLD Loss requires random z in N(0,1)\n",
    "    test_z = Variable(torch.normal(torch.zeros(batch_size, 48),\n",
    "                                   torch.ones(batch_size, 48))).cuda()\n",
    "    test_z = test_z.unsqueeze(0)\n",
    "    kld_loss = kld(torch.log(beta_z), test_z)\n",
    "    \n",
    "    # MSE Loss requires to add displacement at all steps before\n",
    "    y_true = Y_position.permute(2, 0, 1)\n",
    "    mse_loss = mse(y_hat, y_true)\n",
    "    \n",
    "    # Combine losses\n",
    "    loss = kld_loss + mse_loss\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    running_kld_loss += kld_loss.item()\n",
    "    running_mse_loss += mse_loss.item()\n",
    "    running_loss += loss.item()\n",
    "    print('(Epoch %d) Total Loss: %.3f, KLD Loss: %.3f, MSE Loss: %.3f\\n' \n",
    "          % (epoch + 1, running_loss, running_kld_loss, running_mse_loss))\n",
    "    running_kld_loss = 0.0\n",
    "    running_mse_loss = 0.0\n",
    "    \n",
    "# writer.export_scalars_to_json(\"./all_scalars.json\")\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranking & Refinement Module"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
