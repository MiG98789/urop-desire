{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UROP\n",
    "\n",
    "## DESIRE: Distant Future Prediction in Dynamic Scenes with Interacting Agents\n",
    "\n",
    "[CVPR Paper](https://arxiv.org/pdf/1704.04394.pdf)\n",
    "\n",
    "[Supplementary Notes](http://www.robots.ox.ac.uk/~namhoon/doc/DESIRE-supp.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "\n",
    "### Sample Generation Module\n",
    "\n",
    "1) Gradient, i.e. remove straight line/stop (or have some probability of keeping them)\n",
    "\n",
    "2) Data augmentation (rotate trajectories, add Gaussian noise)\n",
    "\n",
    "3) Plot with the map (check manual_control.py of CARLA)\n",
    "\n",
    "### Ranking & Refinement Module\n",
    "\n",
    "1) Finish implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "1. [Sample Generation Module](#sg_module)\n",
    "    \n",
    "    1. [Data](#sg_data)\n",
    "    \n",
    "        1. [Load Dataset](#sg_load_dataset)\n",
    "        \n",
    "        2. [Get Batch](#sg_get_batch)\n",
    "    \n",
    "    2. [Intermediate Models](#sg_intermediate_models)\n",
    "    \n",
    "        1. [Encoder](#sg_encoder)\n",
    "        \n",
    "        2. [CVAE](#sg_cvae)\n",
    "        \n",
    "        3. [FCS](#sg_fcs)\n",
    "        \n",
    "        4. [Decoder](#sg_decoder)\n",
    "    \n",
    "    3. [Sample Generator Model](#sg_model)\n",
    "    \n",
    "    4. [Train](#sg_train)\n",
    "    \n",
    "    5. [Visualise](#sg_vis)\n",
    "    \n",
    "    6. [Test](#sg_test)\n",
    "    \n",
    "2. [Ranking & Refinement Module](#rr_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Generation Module\n",
    "<a id='sg_module'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "<a id='sg_data'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def print_line_sep():\n",
    "    print('--------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset\n",
    "<a id='sg_load_dataset'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def load_dataset(raw_data_path):\n",
    "    raw_data = []\n",
    "    with open(raw_data_path, 'r') as csvfile:\n",
    "        csvreader = csv.reader(csvfile)\n",
    "        raw_data = list(csvreader)\n",
    "    print('Raw data extract: ([time, car, x, y, ...])')\n",
    "    print(raw_data[0])\n",
    "    print_line_sep()\n",
    "\n",
    "    filtered_data = [[int(row[0]), int(row[1]), float(row[2]), float(row[3])] for row in raw_data]\n",
    "    print('Filtered data extract: ([time, car, x, y])')\n",
    "    print(filtered_data[0])\n",
    "    print_line_sep()\n",
    "\n",
    "    car_dict = {}\n",
    "    for row in filtered_data:\n",
    "        time = row[0]\n",
    "        car = row[1]\n",
    "        x = row[2]\n",
    "        y = row[3]\n",
    "\n",
    "        if car in car_dict:\n",
    "            car_dict[car].append([time, x, y])\n",
    "        else:\n",
    "            car_dict[car] = [[time, x, y]]\n",
    "    print('Car dictionary extract: ([time, x, y])')\n",
    "    print(car_dict[filtered_data[0][1]][0])\n",
    "    print_line_sep()\n",
    "\n",
    "    time_dict = {}\n",
    "    for row in filtered_data:\n",
    "        time = row[0]\n",
    "        car = row[1]\n",
    "        x = row[2]\n",
    "        y = row[3]\n",
    "\n",
    "        if time in time_dict:\n",
    "            time_dict[time].append([car, x, y])\n",
    "        else:\n",
    "            time_dict[time] = [[car, x, y]]\n",
    "    print('Time dictionary extract: ([car, x, y])')\n",
    "    print(time_dict[1][0])\n",
    "    \n",
    "    return car_dict, time_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data extract: ([time, car, x, y, ...])\n",
      "['1', '172', '93.939', '-55.7615', '0', '-3.0066', '5.27149', '4', '10']\n",
      "--------------------------------------\n",
      "Filtered data extract: ([time, car, x, y])\n",
      "[1, 172, 93.939, -55.7615]\n",
      "--------------------------------------\n",
      "Car dictionary extract: ([time, x, y])\n",
      "[1, 93.939, -55.7615]\n",
      "--------------------------------------\n",
      "Time dictionary extract: ([car, x, y])\n",
      "[172, 93.939, -55.7615]\n"
     ]
    }
   ],
   "source": [
    "car_dict, time_dict = load_dataset('raw_data/raw_record.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Batch\n",
    "<a id='sg_get_batch'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_batch(x_seq_len, y_seq_len, batch_size, car_dict, time_dict, flag='random', remove_linear=False):\n",
    "    batch = []\n",
    "    \n",
    "    car_dict_keys = list(car_dict.keys())\n",
    "    \n",
    "    time_dict_lengths = {time: len(entries) for time, entries in time_dict.items() if len(entries) >= batch_size}\n",
    "    time_dict_keys = list(time_dict_lengths.keys())\n",
    "    \n",
    "    # Fill up batch with batch_size rows of x+y_seq_len columns\n",
    "    while(len(batch) < batch_size):        \n",
    "        if flag == 'random':\n",
    "            car = random.choice(car_dict_keys)\n",
    "            batch_item = []\n",
    "            is_first_of_sequence = True\n",
    "\n",
    "            # Loop through each row of that car until x_seq_len+y_seq_len columns are found\n",
    "            # TODO: randomise which time sequence taken for each car\n",
    "            for row in car_dict[car]:\n",
    "                time = row[0]\n",
    "                x = row[1]\n",
    "                y = row[2]\n",
    "\n",
    "                # If first item of the sequence, just append\n",
    "                if is_first_of_sequence:\n",
    "                    batch_item.append([time, x, y])\n",
    "                    is_first_of_sequence = False\n",
    "\n",
    "                # Else, check if time diff is 1\n",
    "                else:\n",
    "                    prev_time = batch_item[-1][0]\n",
    "\n",
    "                    # If time diff is not 1, clear batch item, and start from current location as first batch item\n",
    "                    if time - prev_time != 1:\n",
    "                        batch_item = []\n",
    "                        batch_item.append([time, x, y])\n",
    "\n",
    "                    # Else, just append to batch item\n",
    "                    else:\n",
    "                        batch_item.append([time, x, y])\n",
    "                        \n",
    "                # If batch item columns are enough, break\n",
    "                if len(batch_item) == x_seq_len + y_seq_len:\n",
    "                    # TODO: Do not add if straight line or stop by computing second order derivative and see if 0\n",
    "                    if remove_linear:\n",
    "                        if np.abs(batch_item[0][1] - batch_item[-1][1]) > 1 or np.abs(batch_item[0][2] - batch_item[-1][2]) > 1:\n",
    "                            batch.append(batch_item)\n",
    "                            break\n",
    "                                                     \n",
    "                    else:\n",
    "                        batch.append(batch_item)\n",
    "                        break\n",
    "                    \n",
    "        elif flag == 'sync':\n",
    "            start_time = random.choice(time_dict_keys)\n",
    "                        \n",
    "            # Check if there are batch_size number of cars that stay \n",
    "            # from start_time to start_time+x_seq_len+y_seq_len\n",
    "            for row in time_dict[start_time]:\n",
    "                if len(batch) == batch_size:\n",
    "                    break\n",
    "                \n",
    "                car = row[0]\n",
    "                x = row[1]\n",
    "                y = row[2]\n",
    "                batch_item = [[car, x, y]]\n",
    "                    \n",
    "                for time in range(start_time + 1, start_time + x_seq_len + y_seq_len):\n",
    "                    for time_row in time_dict[time]:\n",
    "                        if time_row[0] == car:\n",
    "                            x = time_row[1]\n",
    "                            y = time_row[2]\n",
    "                            batch_item.append([car, x, y])\n",
    "                            break\n",
    "                    \n",
    "                \n",
    "                if len(batch_item) == x_seq_len + y_seq_len:\n",
    "                    # TODO: Do not add if straight line or stop by computing second order derivative and see if 0\n",
    "\n",
    "                    batch.append(batch_item)\n",
    "                    \n",
    "            if len(batch) < batch_size:\n",
    "                batch = []\n",
    "                \n",
    "    # Just keep (x,y)  \n",
    "    X_position_array = [[[item[1], item[2]] for item in batch_item[:x_seq_len]] for batch_item in batch]\n",
    "    Y_position_array = [[[item[1], item[2]] for item in batch_item[x_seq_len:]] for batch_item in batch]\n",
    "    \n",
    "    X_position_np = np.asarray(X_position_array).transpose(0, 2, 1)\n",
    "    Y_position_np = np.asarray(Y_position_array).transpose(0, 2, 1)\n",
    "    \n",
    "    X_position_tensor = torch.from_numpy(X_position_np).type(torch.FloatTensor).cuda()\n",
    "    Y_position_tensor = torch.from_numpy(Y_position_np).type(torch.FloatTensor).cuda()\n",
    "    \n",
    "    # Convert position to displacement\n",
    "    X_displacement_array = []\n",
    "    Y_displacement_array = []\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        x_first = X_position_array[i][0][0]\n",
    "        y_first = X_position_array[i][0][1]\n",
    "\n",
    "        X_batch = X_position_array[i]\n",
    "        X_displacement_array.append([[item[0] - x_first, item[1] - y_first] for item in X_batch])\n",
    "\n",
    "        Y_batch = Y_position_array[i]\n",
    "        Y_displacement_array.append([[item[0] - x_first, item[1] - y_first] for item in Y_batch])\n",
    "\n",
    "    X_displacement_np = np.asarray(X_displacement_array).transpose(0, 2, 1)    \n",
    "    Y_displacement_np = np.asarray(Y_displacement_array).transpose(0, 2, 1)\n",
    "    \n",
    "    X_displacement_tensor = torch.from_numpy(X_displacement_np).type(torch.FloatTensor).cuda()\n",
    "    Y_displacement_tensor = torch.from_numpy(Y_displacement_np).type(torch.FloatTensor).cuda()\n",
    "    \n",
    "    return X_position_tensor, Y_position_tensor, X_displacement_tensor, Y_displacement_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X positions:\n",
      "torch.Size([8, 2, 20])\n",
      "tensor([[  89.8434,   90.2169,   90.5885,   90.9582,   91.3262,   91.6937,\n",
      "           92.0691,   92.4571,   92.8490,   93.2412,   93.6330,   94.0242,\n",
      "           94.4142,   94.8028,   95.1900,   95.5754,   95.9591,   96.3409,\n",
      "           96.7208,   97.0989],\n",
      "        [-330.9990, -330.9940, -330.9880, -330.9830, -330.9780, -330.9730,\n",
      "         -330.9680, -330.9630, -330.9570, -330.9520, -330.9460, -330.9410,\n",
      "         -330.9350, -330.9300, -330.9240, -330.9190, -330.9140, -330.9090,\n",
      "         -330.9030, -330.8980]], device='cuda:0')\n",
      "--------------------------------------\n",
      "Y positions:\n",
      "torch.Size([8, 2, 40])\n",
      "tensor([[  97.4750,   97.8492,   98.2215,   98.5920,   98.9606,   99.3275,\n",
      "           99.6940,  100.0680,  100.4550,  100.8460,  101.2370,  101.6280,\n",
      "          102.0180,  102.4070,  102.7950,  103.1810,  103.5660,  103.9490,\n",
      "          104.3300,  104.7090,  105.0870,  105.4620,  105.8360,  106.2070,\n",
      "          106.5790,  106.9580,  107.3520,  107.7700,  108.2110,  108.6710,\n",
      "          109.1500,  109.6320,  110.0980,  110.5630,  111.0280,  111.4930,\n",
      "          111.9570,  112.4210,  112.8850,  113.4130],\n",
      "        [-330.8930, -330.8880, -330.8830, -330.8770, -330.8720, -330.8670,\n",
      "         -330.8620, -330.8570, -330.8520, -330.8460, -330.8410, -330.8350,\n",
      "         -330.8300, -330.8270, -330.8250, -330.8230, -330.8220, -330.8200,\n",
      "         -330.8190, -330.8180, -330.8170, -330.8160, -330.8160, -330.8150,\n",
      "         -330.8150, -330.8140, -330.8140, -330.8130, -330.8130, -330.8120,\n",
      "         -330.8110, -330.8110, -330.8110, -330.8100, -330.8100, -330.8100,\n",
      "         -330.8090, -330.8090, -330.8090, -330.8090]], device='cuda:0')\n",
      "--------------------------------------\n",
      "X displacements:\n",
      "torch.Size([8, 2, 20])\n",
      "tensor([[ 0.0000,  0.3735,  0.7451,  1.1148,  1.4828,  1.8503,  2.2257,\n",
      "          2.6137,  3.0056,  3.3978,  3.7896,  4.1808,  4.5708,  4.9594,\n",
      "          5.3466,  5.7320,  6.1157,  6.4975,  6.8774,  7.2555],\n",
      "        [ 0.0000,  0.0050,  0.0110,  0.0160,  0.0210,  0.0260,  0.0310,\n",
      "          0.0360,  0.0420,  0.0470,  0.0530,  0.0580,  0.0640,  0.0690,\n",
      "          0.0750,  0.0800,  0.0850,  0.0900,  0.0960,  0.1010]], device='cuda:0')\n",
      "--------------------------------------\n",
      "Y displacements:\n",
      "torch.Size([8, 2, 40])\n",
      "tensor([[  7.6316,   8.0058,   8.3781,   8.7486,   9.1172,   9.4841,\n",
      "           9.8506,  10.2246,  10.6116,  11.0026,  11.3936,  11.7846,\n",
      "          12.1746,  12.5636,  12.9516,  13.3376,  13.7226,  14.1056,\n",
      "          14.4866,  14.8656,  15.2436,  15.6186,  15.9926,  16.3636,\n",
      "          16.7356,  17.1146,  17.5086,  17.9266,  18.3676,  18.8276,\n",
      "          19.3066,  19.7886,  20.2546,  20.7196,  21.1846,  21.6496,\n",
      "          22.1136,  22.5776,  23.0416,  23.5696],\n",
      "        [  0.1060,   0.1110,   0.1160,   0.1220,   0.1270,   0.1320,\n",
      "           0.1370,   0.1420,   0.1470,   0.1530,   0.1580,   0.1640,\n",
      "           0.1690,   0.1720,   0.1740,   0.1760,   0.1770,   0.1790,\n",
      "           0.1800,   0.1810,   0.1820,   0.1830,   0.1830,   0.1840,\n",
      "           0.1840,   0.1850,   0.1850,   0.1860,   0.1860,   0.1870,\n",
      "           0.1880,   0.1880,   0.1880,   0.1890,   0.1890,   0.1890,\n",
      "           0.1900,   0.1900,   0.1900,   0.1900]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Test random batch\n",
    "\n",
    "X_position_test, Y_position_test, X_displacement_test, Y_displacement_test = get_batch(20, 40, 8,\n",
    "                                                                                       car_dict, time_dict,\n",
    "                                                                                       remove_linear=True)\n",
    "\n",
    "print('X positions:')\n",
    "print(X_position_test.size())\n",
    "print(X_position_test[0])\n",
    "\n",
    "print_line_sep()\n",
    "\n",
    "print('Y positions:')\n",
    "print(Y_position_test.size())\n",
    "print(Y_position_test[0])\n",
    "\n",
    "print_line_sep()\n",
    "\n",
    "print('X displacements:')\n",
    "print(X_displacement_test.size())\n",
    "print(X_displacement_test[0])\n",
    "\n",
    "print_line_sep()\n",
    "\n",
    "print('Y displacements:')\n",
    "print(Y_displacement_test.size())\n",
    "print(Y_displacement_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X positions:\n",
      "torch.Size([8, 2, 20])\n",
      "tensor([[ 92.3845,  92.3845,  92.3845,  92.3845,  92.3845,  92.3845,\n",
      "          92.3845,  92.3845,  92.3845,  92.3845,  92.3845,  92.3845,\n",
      "          92.3845,  92.3845,  92.3845,  92.3845,  92.3845,  92.3845,\n",
      "          92.3845,  92.3845],\n",
      "        [-27.9333, -27.9333, -27.9333, -27.9333, -27.9333, -27.9333,\n",
      "         -27.9333, -27.9333, -27.9333, -27.9333, -27.9333, -27.9333,\n",
      "         -27.9333, -27.9333, -27.9333, -27.9333, -27.9333, -27.9333,\n",
      "         -27.9333, -27.9333]], device='cuda:0')\n",
      "--------------------------------------\n",
      "Y positions:\n",
      "torch.Size([8, 2, 40])\n",
      "tensor([[ 92.3845,  92.3845,  92.3845,  92.3845,  92.3845,  92.3845,\n",
      "          92.3845,  92.3845,  92.3845,  92.3845,  92.3845,  92.3845,\n",
      "          92.3845,  92.3845,  92.3845,  92.3845,  92.3845,  92.3845,\n",
      "          92.3845,  92.3845,  92.3845,  92.3845,  92.3845,  92.3845,\n",
      "          92.3845,  92.3845,  92.3845,  92.3845,  92.3845,  92.3845,\n",
      "          92.3845,  92.3845,  92.3845,  92.3845,  92.3845,  92.3845,\n",
      "          92.3845,  92.3845,  92.3845,  92.3845],\n",
      "        [-27.9333, -27.9333, -27.9333, -27.9333, -27.9333, -27.9333,\n",
      "         -27.9333, -27.9333, -27.9333, -27.9333, -27.9333, -27.9333,\n",
      "         -27.9333, -27.9333, -27.9333, -27.9333, -27.9333, -27.9333,\n",
      "         -27.9333, -27.9333, -27.9333, -27.9333, -27.9333, -27.9333,\n",
      "         -27.9333, -27.9333, -27.9333, -27.9333, -27.9333, -27.9333,\n",
      "         -27.9333, -27.9333, -27.9333, -27.9333, -27.9333, -27.9333,\n",
      "         -27.9333, -27.9333, -27.9333, -27.9333]], device='cuda:0')\n",
      "--------------------------------------\n",
      "X displacements:\n",
      "torch.Size([8, 2, 20])\n",
      "tensor([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]], device='cuda:0')\n",
      "--------------------------------------\n",
      "Y displacements:\n",
      "torch.Size([8, 2, 40])\n",
      "tensor([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Test synchronised batch\n",
    "\n",
    "X_position_test, Y_position_test, X_displacement_test, Y_displacement_test = get_batch(20, 40, 8,\n",
    "                                                                                       car_dict, time_dict,\n",
    "                                                                                       flag='sync',\n",
    "                                                                                       remove_linear=True)\n",
    "\n",
    "print('X positions:')\n",
    "print(X_position_test.size())\n",
    "print(X_position_test[0])\n",
    "\n",
    "print_line_sep()\n",
    "\n",
    "print('Y positions:')\n",
    "print(Y_position_test.size())\n",
    "print(Y_position_test[0])\n",
    "\n",
    "print_line_sep()\n",
    "\n",
    "print('X displacements:')\n",
    "print(X_displacement_test.size())\n",
    "print(X_displacement_test[0])\n",
    "\n",
    "print_line_sep()\n",
    "\n",
    "print('Y displacements:')\n",
    "print(Y_displacement_test.size())\n",
    "print(Y_displacement_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intermediate Models\n",
    "<a id='sg_intermediate_models'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder\n",
    "\n",
    "<a id='sg_encoder'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class SampleEncoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_dim, seq_len, num_layers,\n",
    "                 conv_output_dim, conv_kernel_size,\n",
    "                 gru_hidden_dim):\n",
    "        super(SampleEncoder, self).__init__()\n",
    "        \n",
    "        self.seq_len = seq_len\n",
    "        self.num_layers = num_layers\n",
    "        self.conv_output_dim = conv_output_dim\n",
    "        self.conv_kernel_size = conv_kernel_size\n",
    "        self.gru_hidden_dim = gru_hidden_dim\n",
    "        \n",
    "        # C = X or Y\n",
    "        # C_i, (input_dim, seq_len) -> tC_i, (conv_output_dim, seq_len)\n",
    "        self.conv = nn.Conv1d(input_dim, conv_output_dim, conv_kernel_size)\n",
    "\n",
    "        # tC_i, (conv_output_dim, seq_len) -> H_C_i, (gru_hidden_dim)\n",
    "        self.gru = nn.GRU(conv_output_dim, gru_hidden_dim, num_layers)\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        # Initial hidden vector is hidden_dim-dimensional and padded with 0\n",
    "        return Variable(torch.zeros(self.num_layers, batch_size, self.gru_hidden_dim)).cuda()\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        conv_output = self.conv(x)\n",
    "        conv_output = F.relu(conv_output)\n",
    "        \n",
    "        # conv_output has dimensions (batch_size, dim, seq_len)\n",
    "        # GRU accepts input tensor with dimensions (seq_len, batch_size, dim)\n",
    "        # TODO: Pad\n",
    "        conv_output = conv_output.permute(2, 0, 1)\n",
    "        \n",
    "        output, hidden = self.gru(conv_output, hidden)\n",
    "        \n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Variational Auto Encoder\n",
    "<a id='sg_cvae'></a>\n",
    "\n",
    "#### Reparamerisation Trick\n",
    "\n",
    "$$ z = \\mu + \\sigma \\boxtimes \\epsilon, \\epsilon \\text{ ~ } N(0,1) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class SampleCVAE(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, mu_dim, sigma_dim):\n",
    "        super(SampleCVAE, self).__init__()\n",
    "        \n",
    "        self.sigma_dim = sigma_dim\n",
    "\n",
    "        self.fc1 = nn.Linear(input_dim, output_dim)\n",
    "        self.fc_mu = nn.Linear(output_dim, mu_dim)\n",
    "        self.fc_sigma = nn.Linear(output_dim, sigma_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        output = self.fc1(x)\n",
    "        output = F.relu(output)\n",
    "        \n",
    "        mu = self.fc_mu(output)\n",
    "        sigma = torch.div(torch.exp(self.fc_sigma(output)), 2)\n",
    "        epsilon = F.softmax(torch.randn(batch_size, 48), 1).cuda()\n",
    "        # Reparam trick\n",
    "        z = mu + sigma*epsilon\n",
    "\n",
    "        return z, mu, sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Connected Softmax Layer\n",
    "<a id='sg_fcs'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class SampleFCS(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(SampleFCS, self).__init__()\n",
    "        \n",
    "        self.fcs = nn.Linear(input_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.fcs(x)\n",
    "        output = F.log_softmax(output, dim=2)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder\n",
    "<a id='sg_decoder'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class SampleDecoder(nn.Module):\n",
    "    def __init__(self, input_dim, seq_len, num_layers, gru_hidden_dim, gru_output_dim, output_dim):\n",
    "        super(SampleDecoder, self).__init__()\n",
    "        \n",
    "        self.seq_len = seq_len\n",
    "        self.num_layers = num_layers\n",
    "        self.gru_hidden_dim = gru_hidden_dim\n",
    "        \n",
    "        self.gru = nn.GRU(input_dim, gru_output_dim, num_layers)\n",
    "        self.linear = nn.Linear(gru_output_dim, output_dim)\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        return Variable(torch.zeros(self.num_layers, batch_size, self.gru_hidden_dim)).cuda()\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        output, hidden = self.gru(x, hidden)\n",
    "        output = self.linear(output)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Generator Model\n",
    "<a id='sg_model'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleGenerator(nn.Module):\n",
    "    def __init__(self, X_seq_len, Y_seq_len):\n",
    "        super(SampleGenerator, self).__init__()\n",
    "        \n",
    "        self.X_seq_len = X_seq_len\n",
    "        self.Y_seq_len = Y_seq_len\n",
    "        \n",
    "        # input_dim = 2        | input is a sequence of (x,y) coordinates (i.e. 2-dimensional)\n",
    "        # seq_len = 20         | time sequence length of 20\n",
    "        # conv_output_dim = 16 | 1D convolution with 16 output channels\n",
    "        # conv_kernel_size = 3 | 1D convolution with kernel of width 3\n",
    "        # gru_hidden_dim = 48  | 48-dimensional hidden vector\n",
    "        #\n",
    "        # Input: Tensor of size (batch_size, 2, 20)\n",
    "        self.encoder1 = SampleEncoder(input_dim=2, seq_len=X_seq_len, num_layers=1,\n",
    "                                 conv_output_dim=16, conv_kernel_size=3,\n",
    "                                 gru_hidden_dim=48).cuda()\n",
    "\n",
    "        # input_dim = 2        | input is a sequence of (x,y) coordinates (i.e. 2-dimensional)\n",
    "        # seq_len = 40         | time sequence length of 40\n",
    "        # conv_output_dim = 16 | 1D convolution with 16 output channels\n",
    "        # conv_kernel_size = 1 | 1D convolution with kernel of width 1\n",
    "        # gru_hidden_dim = 48  | 48-dimensional hidden vector\n",
    "        #\n",
    "        # Input: Tensor of size (batch_size, 2, 40)\n",
    "        self.encoder2 = SampleEncoder(input_dim=2, seq_len=Y_seq_len, num_layers=1,\n",
    "                                 conv_output_dim=16, conv_kernel_size=1,\n",
    "                                 gru_hidden_dim=48).cuda()\n",
    "\n",
    "        # input_dim = 96       | Concatenate encoder1's and encoder2's outputs (48-dim each) into 1 output (96-dim)\n",
    "        # output_dim = 48      | Transform concatenated 96-dim vector into 48-dim vector\n",
    "        # mu_dim = 48          | mu is 48-dim\n",
    "        # sigma_dim = 48       | sigma is 48-dim\n",
    "        #\n",
    "        # Input: Tensor of size (batch_size, 48)\n",
    "        self.cvae = SampleCVAE(input_dim=96, output_dim=48, mu_dim=48, sigma_dim=48).cuda()\n",
    "\n",
    "        # input_dim = 48       |\n",
    "        # output_dim = 48      |\n",
    "        #\n",
    "        # Input: Tensor of size (batch_size, 48)\n",
    "        self.fcs = SampleFCS(input_dim=48, output_dim=48).cuda()\n",
    "\n",
    "        # input_dim = 48       |\n",
    "        # seq_len = 40         | time sequence length of 40\n",
    "        # gru_hidden_dim = 48  |\n",
    "        # gru_output_dim = 48  |\n",
    "        # output_dim = 2       |\n",
    "        #\n",
    "        # Input: Tensor of size (40, batch_size, 48)\n",
    "        self.decoder1 = SampleDecoder(input_dim=48, seq_len=40, num_layers=1,\n",
    "                                gru_hidden_dim=48, gru_output_dim=48,\n",
    "                                output_dim=2).cuda()\n",
    "        \n",
    "    def forward(self, x, batch_size, flag, input_z=None):\n",
    "        if flag == 'train':\n",
    "            X_position = x[0]\n",
    "            Y_position = x[1]\n",
    "            X_displacement = x[2]\n",
    "            Y_displacement = x[3]\n",
    "\n",
    "            # Encoder 1\n",
    "            e1_hidden = self.encoder1.init_hidden(batch_size)\n",
    "            e1_output, e1_last_hidden = self.encoder1(X_displacement, e1_hidden)\n",
    "            H_X = e1_last_hidden\n",
    "\n",
    "            # Encoder 2\n",
    "            e2_hidden = self.encoder2.init_hidden(batch_size)\n",
    "            e2_output, e2_last_hidden = self.encoder2(Y_displacement, e2_hidden)\n",
    "            H_Y = e2_last_hidden\n",
    "\n",
    "            # CVAE\n",
    "            H_XY = torch.cat([H_X, H_Y], 2)\n",
    "            z, mu, sigma = self.cvae(H_XY)\n",
    "\n",
    "            # FCS\n",
    "            beta_z = self.fcs(z)\n",
    "\n",
    "            # Decoder\n",
    "            xz = H_X*beta_z\n",
    "            hxz = xz\n",
    "            for i in range(39):\n",
    "                hxz = torch.cat((hxz, Variable(torch.zeros(1, batch_size, 48)).cuda()), 0)\n",
    "            decoder_hidden = self.decoder1.init_hidden(batch_size)\n",
    "            output, last_hidden = self.decoder1(hxz, decoder_hidden)\n",
    "\n",
    "            # Reconstruction\n",
    "            X0 = X_position.permute(2, 0, 1)[-1]\n",
    "            delta_X0 = output[0]    \n",
    "            Y0_hat = X0 + delta_X0\n",
    "            Y_hat = Y0_hat.unsqueeze(0)\n",
    "\n",
    "            for i in range(1, Y_seq_len):\n",
    "                Yi = Y_hat[i - 1]\n",
    "                delta_Xi = output[i]\n",
    "                Yi_hat = Yi + delta_Xi\n",
    "                Yi_hat = Yi_hat.unsqueeze(0)\n",
    "                Y_hat = torch.cat((Y_hat, Yi_hat), 0)\n",
    "            #Y_hat = Y_hat.permute(1, 2, 0)\n",
    "\n",
    "            return Y_hat, beta_z, mu, sigma\n",
    "        \n",
    "        elif flag == 'test':\n",
    "            X_position = x[0]\n",
    "            X_displacement = x[1] \n",
    "            \n",
    "            # Encoder 1\n",
    "            e1_hidden = self.encoder1.init_hidden(batch_size)\n",
    "            e1_output, e1_last_hidden = self.encoder1(X_displacement, e1_hidden)\n",
    "            H_X = e1_last_hidden\n",
    "\n",
    "            # FCS\n",
    "            beta_z = self.fcs(input_z)\n",
    "\n",
    "            # Decoder\n",
    "            xz = H_X*beta_z\n",
    "            hxz = xz\n",
    "            for i in range(39):\n",
    "                hxz = torch.cat((hxz, Variable(torch.zeros(1, batch_size, 48)).cuda()), 0)\n",
    "            decoder_hidden = self.decoder1.init_hidden(batch_size)\n",
    "            output, last_hidden = self.decoder1(hxz, decoder_hidden)\n",
    "\n",
    "            # Reconstruction\n",
    "            X0 = X_position.permute(2, 0, 1)[-1]\n",
    "            delta_X0 = output[0]    \n",
    "            Y0_hat = X0 + delta_X0\n",
    "            Y_hat = Y0_hat.unsqueeze(0)\n",
    "\n",
    "            for i in range(1, Y_seq_len):\n",
    "                Yi = Y_hat[i - 1]\n",
    "                delta_Xi = output[i]\n",
    "                Yi_hat = Yi + delta_Xi\n",
    "                Yi_hat = Yi_hat.unsqueeze(0)\n",
    "                Y_hat = torch.cat((Y_hat, Yi_hat), 0)\n",
    "            #Y_hat = Y_hat.permute(1, 2, 0)\n",
    "                \n",
    "            return Y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "<a id='sg_train'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_loss(Y_hat, Y_true, mu, sigma):\n",
    "    mse_loss = nn.MSELoss()(Y_hat, Y_true)\n",
    "    kld_loss = -0.5*torch.sum(1 + sigma - mu.pow(2) - sigma.exp())\n",
    "    loss = mse_loss + kld_loss\n",
    "    return loss, mse_loss, kld_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 0) Total Loss: 88.418, KLD Loss: 40.350, MSE Loss: 48.068\n",
      "(Epoch 100) Total Loss: 50.847, KLD Loss: 24.945, MSE Loss: 25.902\n",
      "(Epoch 200) Total Loss: 32.289, KLD Loss: 16.800, MSE Loss: 15.489\n",
      "(Epoch 300) Total Loss: 35.174, KLD Loss: 6.201, MSE Loss: 28.974\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 1000\n",
    "batch_size = 8\n",
    "X_seq_len = 20\n",
    "Y_seq_len = 40\n",
    "save_path = 'save/sample_generator.pt'\n",
    "\n",
    "# Initialize model\n",
    "sample_generator = SampleGenerator(X_seq_len, Y_seq_len)\n",
    "\n",
    "# Loss\n",
    "all_kld_loss = []\n",
    "all_mse_loss = []\n",
    "all_loss = []\n",
    "\n",
    "all_mu = None\n",
    "all_sigma = None\n",
    "last_X_true = None\n",
    "last_Y_true = None\n",
    "last_Y_hat = None\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(sample_generator.parameters(), lr=learning_rate)\n",
    "\n",
    "# writer = SummaryWriter()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    X_position, Y_position, X_displacement, Y_displacement = get_batch(X_seq_len, Y_seq_len, batch_size,\n",
    "                                                                       car_dict, time_dict,\n",
    "                                                                       remove_linear=True)\n",
    "    \n",
    "#     writer.add_scalars('data/X', {\n",
    "#         'x': X.permute(0, 2, 1)[0][0][0],\n",
    "#         'y': Y.permute(0, 2, 1)[0][0][0]\n",
    "#     }, epoch)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    Y_hat, beta_z, mu, sigma = sample_generator([X_position, Y_position, X_displacement, Y_displacement],\n",
    "                                                     batch_size, flag='train')\n",
    "    all_mu = mu if all_mu is None else torch.cat((all_mu, mu), 0)\n",
    "    all_sigma = sigma if all_sigma is None else torch.cat((all_sigma, sigma), 0)\n",
    "        \n",
    "    # Minimise loss\n",
    "    Y_true = Y_position.permute(2, 0, 1)\n",
    "    loss, mse_loss, kld_loss = get_training_loss(Y_hat, Y_true, mu, sigma)\n",
    "    loss.backward()\n",
    "    all_kld_loss.append(kld_loss.item())\n",
    "    all_mse_loss.append(mse_loss.item())\n",
    "    all_loss.append(loss.item())\n",
    "\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % (num_epochs/10) == 0:\n",
    "        print('(Epoch %d) Total Loss: %.3f, KLD Loss: %.3f, MSE Loss: %.3f' \n",
    "          % (epoch, all_loss[epoch], all_kld_loss[epoch], all_mse_loss[epoch]))\n",
    "    \n",
    "    if epoch + 1 == num_epochs:\n",
    "        print('(Epoch %d) Total Loss: %.3f, KLD Loss: %.3f, MSE Loss: %.3f' \n",
    "          % (num_epochs, all_loss[epoch], all_kld_loss[epoch], all_mse_loss[epoch]))\n",
    "        print('Completed training')\n",
    "        \n",
    "        torch.save(sample_generator.state_dict(), save_path)\n",
    "        \n",
    "        last_X_true = X_position\n",
    "        last_Y_true = Y_true.permute(1, 2, 0)\n",
    "        last_Y_hat = Y_hat.permute(1, 2, 0)\n",
    "        all_mu = all_mu.permute(1, 0, 2)\n",
    "        all_sigma = all_sigma.permute(1, 0, 2)\n",
    "        \n",
    "# writer.export_scalars_to_json(\"./all_scalars.json\")\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise\n",
    "<a id='sg_visualise'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_trajectories(X_true, Y_hats, Y_true, batch_size):\n",
    "    # Plot all trajectories of the batch\n",
    "    traj_fig = plt.figure(figsize=(20, 20))\n",
    "    traj_fig.tight_layout()        \n",
    "    for i in range(batch_size):\n",
    "        ax = traj_fig.add_subplot(batch_size/2, batch_size - batch_size/2, i + 1)\n",
    "\n",
    "        ax.plot(X_true[i][0].cpu().detach().numpy(),\n",
    "                X_true[i][1].cpu().detach().numpy(),\n",
    "                linestyle='-', marker='o', color='y', label='Past')\n",
    "\n",
    "        for j in range(len(Y_hats)):\n",
    "            Y_hat = Y_hats[j]\n",
    "\n",
    "            if j == 0:\n",
    "                ax.plot(Y_hat[i][0].cpu().detach().numpy(),\n",
    "                        Y_hat[i][1].cpu().detach().numpy(),\n",
    "                        linestyle='-', marker='o', color='r', label='Reconstructed')\n",
    "            else:\n",
    "                ax.plot(Y_hat[i][0].cpu().detach().numpy(),\n",
    "                        Y_hat[i][1].cpu().detach().numpy(),\n",
    "                        linestyle='-', marker='o', color='r')\n",
    "\n",
    "        ax.plot(Y_true[i][0].cpu().detach().numpy(),\n",
    "                Y_true[i][1].cpu().detach().numpy(),\n",
    "                linestyle='-', marker='o', color='b', label='True')\n",
    "\n",
    "        if i == 0:\n",
    "            ax.legend(loc='upper left')\n",
    "            ax.set_xlabel('x-coordinate')\n",
    "            ax.set_ylabel('y-coordinate')\n",
    "\n",
    "        X_true_x_min = X_true[i][0].cpu().detach().numpy().min()\n",
    "        X_true_x_max = X_true[i][0].cpu().detach().numpy().max()\n",
    "        X_true_y_min = X_true[i][1].cpu().detach().numpy().min()\n",
    "        X_true_y_max = X_true[i][1].cpu().detach().numpy().max()\n",
    "\n",
    "        Y_hat_x_min = Y_hats[0][i][0].cpu().detach().numpy().min()\n",
    "        Y_hat_x_max = Y_hats[0][i][0].cpu().detach().numpy().max()\n",
    "        Y_hat_y_min = Y_hats[0][i][1].cpu().detach().numpy().min()\n",
    "        Y_hat_y_max = Y_hats[0][i][1].cpu().detach().numpy().max()\n",
    "        for j in range(1, len(Y_hats)):        \n",
    "            Y_hat_x_min = Y_hat_x_min if Y_hat_x_min < Y_hats[j][i][0].cpu().detach().numpy().min() else Y_hats[j][i][0].cpu().detach().numpy().min()\n",
    "            Y_hat_x_max = Y_hat_x_max if Y_hat_x_max > Y_hats[j][i][0].cpu().detach().numpy().max() else Y_hats[j][i][0].cpu().detach().numpy().max()\n",
    "            Y_hat_y_min = Y_hat_y_min if Y_hat_y_min < Y_hats[j][i][1].cpu().detach().numpy().min() else Y_hats[j][i][1].cpu().detach().numpy().min()\n",
    "            Y_hat_y_max = Y_hat_y_max if Y_hat_y_max > Y_hats[j][i][1].cpu().detach().numpy().max() else Y_hats[j][i][1].cpu().detach().numpy().max()\n",
    "        \n",
    "        Y_true_x_min = Y_true[i][0].cpu().detach().numpy().min()\n",
    "        Y_true_x_max = Y_true[i][0].cpu().detach().numpy().max()\n",
    "        Y_true_y_min = Y_true[i][1].cpu().detach().numpy().min()\n",
    "        Y_true_y_max = Y_true[i][1].cpu().detach().numpy().max()\n",
    "\n",
    "        xy_x_min = np.sort(np.array([X_true_x_min, Y_true_x_min, Y_hat_x_min]), axis=None)[0]\n",
    "        xy_x_max = np.sort(np.array([X_true_x_max, Y_true_x_max, Y_hat_x_max]), axis=None)[-1]\n",
    "        xy_y_min = np.sort(np.array([X_true_y_min, Y_true_y_min, Y_hat_y_min]), axis=None)[0]\n",
    "        xy_y_max = np.sort(np.array([X_true_y_max, Y_true_y_max, Y_hat_y_max]), axis=None)[-1]\n",
    "\n",
    "        xy_delta = xy_x_max - xy_x_min if xy_x_max - xy_x_min > xy_y_max - xy_y_min else xy_y_max - xy_y_min\n",
    "\n",
    "        ax.set_xlim(xy_x_min - 10, xy_x_min + xy_delta + 10)\n",
    "        ax.set_ylim(xy_y_min - 10, xy_y_min + xy_delta + 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot losses\n",
    "loss_fig = plt.figure(figsize=(20, 5))\n",
    "ax = loss_fig.add_subplot(1, 1, 1)\n",
    "ax.plot(range(num_epochs), all_kld_loss, linestyle='-', color='c', label='KLD Loss')\n",
    "ax.plot(range(num_epochs), all_mse_loss, linestyle='-', color='g', label='MSE Loss')\n",
    "ax.plot(range(num_epochs), all_loss, linestyle='-', color='k', label='Total Loss')\n",
    "ax.set_title('Sample Generation')\n",
    "ax.legend(loc='upper left')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')\n",
    "\n",
    "# Plot mu and sigma\n",
    "cvae_fig = plt.figure(figsize=(20, 20))\n",
    "cvae_fig.tight_layout()\n",
    "first_cvae_fig_ax = None\n",
    "for i in range(batch_size):    \n",
    "    ax = cvae_fig.add_subplot(batch_size/2, batch_size - batch_size/2, i + 1)\n",
    "    ax.plot(range(num_epochs), all_mu[i].cpu().detach().numpy(), linestyle='-', color='c', label='mu')\n",
    "    ax.plot(range(num_epochs), all_sigma[i].cpu().detach().numpy(), linestyle='-', color='m', label='sigma')\n",
    "        \n",
    "    if i == 0:\n",
    "        first_cvae_fig_ax = ax\n",
    "        ax.set_xlabel('Epoch')\n",
    "        ax.set_ylabel('Value')\n",
    "        \n",
    "    if i == batch_size - 1:\n",
    "        handles, labels = cvae_fig.gca().get_legend_handles_labels()\n",
    "        j = 1\n",
    "        while j < len(labels):\n",
    "            if labels[j] in labels[:j]:\n",
    "                del(labels[j])\n",
    "                del(handles[j])\n",
    "            else:\n",
    "                j += 1\n",
    "        first_cvae_fig_ax.legend(handles, labels, loc='upper left')\n",
    "\n",
    "visualise_trajectories(last_X_true, [last_Y_hat], last_Y_true, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "<a id='sg_test'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample_generator = SampleGenerator(X_seq_len, Y_seq_len)\n",
    "test_sample_generator.load_state_dict(torch.load(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_position, Y_position, X_displacement, Y_displacement = get_batch(X_seq_len, Y_seq_len, batch_size,\n",
    "                                                                   car_dict, time_dict,\n",
    "                                                                   remove_linear=True)\n",
    "num_predictions = 10\n",
    "Y_hats = []\n",
    "\n",
    "# Generate list of random z\n",
    "for i in range(num_predictions):\n",
    "    z = torch.randn(batch_size, 48).cuda().unsqueeze(0)\n",
    "    Y_hat = test_sample_generator([X_position, X_displacement],\n",
    "                                       batch_size, flag='test', input_z=z)\n",
    "    Y_hats.append(Y_hat.permute(1, 2, 0))\n",
    "\n",
    "# Plot\n",
    "traj_fig = plt.figure(figsize=(20, 20))\n",
    "traj_fig.tight_layout()\n",
    "X_true = X_position\n",
    "Y_true = Y_position.permute(2, 0, 1).permute(1, 2, 0)\n",
    "\n",
    "visualise_trajectories(X_true, Y_hats, Y_true, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranking & Refinement Module\n",
    "<a id='rr_module'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
